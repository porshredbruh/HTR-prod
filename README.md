# HTR-prod
<p align="center">
    <img src="https://i.postimg.cc/C1Wd6R73/IMG-20250309-193541-418.jpg" alt="htr_logo" width="780" height="auto">
</p>


## О проекте

В наше время люди в различных сферах деятельности сталкиваются с проблемой необходимости эффективного управления объёмными массивами информации, включая рукописные заметки, лекции и другие документы.

Целью проекта стало решении проблемы оцифровки рукописного текста с использованием технологий искусственного интеллекта для автоматизации процесса сегментации и распознавания рукописных записей.

## Что уникально?

- Реализовано распознавание чертежей(или прочих рисунков), рукописного текста и математических выражений
- Реализована оцифровка текста и математических выражений
- Создано простое для использования и интуитивно понятное Android приложение
- Датасет, состоящий более чем из 1000 самостоятельно аннотированных изображений.

## Принцип работы

1. Изображение приходит на сервер от пользователя.
2. Определение объектов(text, math и image) моделью Object detection.
3. Объекты класса text и math отправляются в соответствующие OCR модели.
4. Собирается файл docx с содержанием аналогичным по расположению объектов на исходной фотографии.
5. Файл docx сохраняется в хранилище телефона пользователя.


<p align="center">
    <img src="https://i.postimg.cc/TYx3LM4J/1.png" alt="htr_logo" width="780" height="auto">
</p>
   
## Технический стек

- Machine Learning:
    - Object detection: Faster R-CNN
    - OCR: кастомный класс на TransformerModelOCR
- Мобильная разработка: Android Studio, Java
- Backend: Uvicorn

## Модели

### Object detection 

Модель детектирует на изображении объекты 3-х классов: 
- text (основной текст)
- math (математические формулы)
- image (чертежи, рисунки)

В ходе разработки эксперементировал с выбором модели. Вот лучшие результаты, которых получилось добиться:
| Модель        | mAP      | F1-Score | Loss     |
| :-------------| :---:    | :------: | :----:   |
| Faster R-CNN  | 0.826859 | 0.866175 | 0.146773 |
| YOLOv5        | 0.705259 | 0.717947 | 0.246662 |
| RetinaNET     | 0.654271 | 0.699593 | 0.270770 |
| EfficientDet  | 0.617148 | 0.650774 | 0.283843 |

Faster R-CNN является "абсолютным победителем", поэтому его и использую.

### OCR

После выделения bounding box-ов объекты классов text и math отправляются в 2 разные OCR модели. Text переводится в машинописный вид, math - конвертируется в LaTeX. 
<br><br>
Для моделей я использую самописный класс на TransformerModelOCR.

## Android приложение

Реализовано на Java. Имеет следующий функционал:
- Смена языка
- Обучение
- Возможность выбрать фото из галереи
- Возможность сделать фотографию внутри и сразу загрузить

## Документация

### 1. Подготовка окружения

1. Убедитесь, что у вас установлен Python 3.7+ (или более поздняя версия).
2. Перейдите в директорию с распакованным проектом:  
3. Создайте виртуальное окружение (рекомендуется). Например:
   ```
   python -m venv venv
   source venv/bin/activate   # для Linux/Mac
   venv\Scripts\activate      # для Windows
   ```
   
4. Установите зависимости из requirements.txt:
   ```
   pip install -r requirements.txt
   ```
___

### 2. Назначение файлов

Внутри папки Train имеются следующие файлы:

1. `Train-OD.ipynb`  
   – Jupiter Notebook с кодом обучения для Object Detection.

2. `Train-OCR.ipynb`  
   – Jupiter Notebook с кодом обучения для OCR(text).

3. `Train-math.ipynb`  
   – Jupiter Notebook с кодом обучения для OCR(math).

4. `utils.py`  
   – Утилитные функции для обучения и логирования (метрики, функции для синхронизации между процессами, метод для усреднения значений SmoothedValue и т.п.).

5. `requirements.txt`  
   – Список необходимых Python-библиотек. Устанавливаются командой:

   ```
    pip install -r requirements.txt.
    ```
    
6. `coco_eval.py`  
   – Скрипт для оценки результатов детектирования с помощью COCO API (вычисление mAP и других метрик).

7. `coco_utils.py`  
   – Дополнительные утилиты для работы с COCO-датасетом: преобразование аннотаций, фильтрация, генерация масок и т.д.

8. `engine.py`  
   – Основной “движок” обучения.

Уточнение: файлы `utils.py`, `coco_eval.py`, `coco_utils.py`, `engine.py` взяты из открытого [репозитория PyTorch](https://github.com/pytorch/vision/blob/main/references/detection/)

___

### 3. Обучение моделей

#### 3.1. Train-OD.ipynb

1. Запустите Jupyter Notebook (или любую другую поддерживающую среду)
2. Откройте файл `Train-OD.ipynb`.
3. Настройте пути к данным.
   Убедитесь, что:
   
   - папка ./train/images существует и содержит необходимые изображения;
   - папка ./train/annotations существует и содержит аннотации.
4. Запустите обучение.

___

### 3.2. Train-OCR.ipynb

1. Запускаем аналогично.
2. Обратите внимание на переменные в начале файла:
   ```
   DIR = './'
   PATH_TEST_DIR = './test/'
   PATH_TEST_LABELS =  './test.tsv'
   PATH_TRAIN_DIR =  './train/'
   PATH_TRAIN_LABELS =  './train.tsv'
   ...
   WEIGHTS_PATH =  "./ocr_transformer.pth"
   ```
   Проверьте, что нужные файлы и папки существуют, или измените пути на актуальные.
   
3. Запустите обучение.

___

### 3.3. Train-math.ipynb

1. Запускаем аналогично.
2. Обратите внимание на переменные в начале файла:
   ```
   DIR = './'
   PATH_TEST_DIR = './test/'
   PATH_TEST_LABELS =  './test.tsv'
   PATH_TRAIN_DIR =  './train/'
   PATH_TRAIN_LABELS =  './train.tsv'
   ...
   WEIGHTS_PATH =  "./ocr_transformer.pth"
   ```
   Проверьте, что нужные файлы и папки существуют, или измените пути на актуальные.
   
3. Запустите обучение.

___

## План развития

1. Краткосрочные цели
    - Улучшение точности распознавания
    - Оптимизация производительности
    - Расширение поддерживаемых форматов вывода

2. Долгосрочные цели

    - Интеграция с облачными сервисами
    - Добавление функций перевода языков
    - Автоматический анализ текста, контекстные добавления и исправления
    - Расширение обучающей выборки
    - Расширение функционала приложения
